{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## RDP Learning\n",
    "\n",
    "In this notebook, we show how to perform PAC learning\n",
    "over RDPs.\n",
    "\n",
    "### Experiment 1: Rotating MAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Discrete(2)\n",
      "Action space: Discrete(2)\n",
      "Initial state: 0\n",
      "----------\n",
      "Action: 0\n",
      "Next state: 1\n",
      "Reward: 1.0\n",
      "----------\n",
      "Action: 0\n",
      "Next state: 1\n",
      "Reward: 1.0\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from typing import Callable, Sequence\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym.wrappers import TimeLimit\n",
    "from src import NonMarkovianRotatingMAB\n",
    "from src.learn_pdfa.base import learn_pdfa\n",
    "from src.learn_pdfa.common import Generator, PalmerParams, MultiprocessedGenerator\n",
    "from src.learn_pdfa.learn_subgraph import learn_subgraph\n",
    "from src.pdfa import PDFA\n",
    "from src.pdfa.types import Word\n",
    "\n",
    "env = NonMarkovianRotatingMAB(winning_probs=[0.9, 0.2])\n",
    "\n",
    "print(f\"Observation space: {env.observation_space}\")\n",
    "print(f\"Action space: {env.action_space}\")\n",
    "\n",
    "s = env.reset()\n",
    "print(f\"Initial state: {s}\")\n",
    "\n",
    "action = 0\n",
    "sp, reward, _, _ = env.step(action)\n",
    "print(\"-\" * 10)\n",
    "print(f\"Action: {action}\")\n",
    "print(f\"Next state: {sp}\")\n",
    "print(f\"Reward: {reward}\")\n",
    "\n",
    "sp, reward, _, _ = env.step(action)\n",
    "print(\"-\" * 10)\n",
    "print(f\"Action: {action}\")\n",
    "print(f\"Next state: {sp}\")\n",
    "print(f\"Reward: {reward}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class RDPGenerator(Generator):\n",
    "    \"\"\"Generate a trace against.\"\"\"\n",
    "\n",
    "    def __init__(self, env: gym.Env, policy: Callable, stop_probability: float = 0.05):\n",
    "        self._env = env\n",
    "        self._policy = policy\n",
    "        self._stop_probability = stop_probability\n",
    "\n",
    "        self.obs_space_dim = self._env.observation_space.n\n",
    "        self.action_dim = self._env.action_space.n\n",
    "        self.nb_rewards = 2  # TODO fix\n",
    "        self._encoder = partial(np.ravel_multi_index, dims=(self.action_dim, self.nb_rewards, self.obs_space_dim))\n",
    "\n",
    "    def alphabet_size(self) -> int:\n",
    "        \"\"\"Get the alphabet size.\"\"\"\n",
    "        return int(np.prod([self.action_dim, self.nb_rewards, self.obs_space_dim]))\n",
    "\n",
    "    def sample(self, n: int = 1) -> Sequence[Word]:\n",
    "        result = []\n",
    "        for _ in range(n):\n",
    "            word = self._sample_word()\n",
    "            result.append(word)\n",
    "        return result\n",
    "\n",
    "    def _should_stop(self) -> bool:\n",
    "        \"\"\"Return True if the current episode should stop, false otherwise.\"\"\"\n",
    "        return np.random.random() < self._stop_probability\n",
    "\n",
    "    def _sample_word(self) -> Word:\n",
    "        \"\"\"Sample one word.\"\"\"\n",
    "        initial_state = self._env.reset()\n",
    "        done = False\n",
    "        trace = [(0, 0, initial_state)]\n",
    "        while not done:\n",
    "            if self._should_stop():\n",
    "                break\n",
    "            action = self._policy()\n",
    "            obs, reward, done, _ = self._env.step(action)\n",
    "            trace += [(action, int(reward), obs)]\n",
    "\n",
    "        trace = [self._encoder(x) for x in trace]\n",
    "        return trace"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "stop_probability = 0.05\n",
    "winning_probs = (1.0, 0.0)\n",
    "optimal_avg_reward = max(winning_probs)\n",
    "env = gym.make(\"NonMarkovianRotatingMAB-v0\", winning_probs=winning_probs)\n",
    "env = TimeLimit(env, max_episode_steps=4)\n",
    "\n",
    "def exploration_policy(env: gym.Env):\n",
    "    return env.action_space.sample()\n",
    "policy = partial(exploration_policy, env)\n",
    "\n",
    "rdp_generator = RDPGenerator(env, policy=policy, stop_probability=stop_probability)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apriori expected length of traces: 1/stop_prob = 20.0\n",
      "Average length of traces: 4.549\n"
     ]
    }
   ],
   "source": [
    "examples = rdp_generator.sample(n=1000)\n",
    "\n",
    "print(f\"Apriori expected length of traces: 1/stop_prob = {1/stop_probability}\")\n",
    "print(f\"Average length of traces: {np.mean([len(e) for e in examples])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-10-30 20:30:33,352][src.learn_pdfa][INFO] Parameters: ('PalmerParams(sample_generator=<src.learn_pdfa.common.MultiprocessedGenerator '\n",
      " 'object at 0x7f63e6176890>, alphabet_size=8, epsilon=0.4, delta_1=0.2, '\n",
      " 'delta_2=0.2, mu=0.2, n=3, m0_max_debug=10000, n1_max_debug=300000, '\n",
      " 'n2_max_debug=300000)')\n",
      "[2020-10-30 20:30:33,353][src.learn_pdfa][INFO] N1 = 616983.093395157, N2 = 57183600.0. Chosen: 57183600\n",
      "[2020-10-30 20:30:33,353][src.learn_pdfa][INFO] m0 = 238265\n",
      "[2020-10-30 20:30:33,354][src.learn_pdfa][INFO] N = 57183600\n",
      "[2020-10-30 20:30:33,354][src.learn_pdfa][INFO] using m0 = 10000, N = 300000\n",
      "[2020-10-30 20:30:54,817][src.learn_pdfa][INFO] Sampling done.\n",
      "[2020-10-30 20:30:54,818][src.learn_pdfa][INFO] Number of samples: 300000.\n",
      "[2020-10-30 20:30:54,840][src.learn_pdfa][INFO] Avg. length of samples: 4.536053333333333.\n",
      "[2020-10-30 20:30:55,237][src.learn_pdfa][INFO] Iteration 0\n",
      "[2020-10-30 20:30:56,310][src.learn_pdfa][INFO] Iteration 1\n",
      "[2020-10-30 20:30:57,680][src.learn_pdfa][INFO] Iteration 2\n",
      "[2020-10-30 20:30:59,087][src.learn_pdfa][INFO] Iteration 3\n",
      "[2020-10-30 20:31:00,581][src.learn_pdfa][INFO] Iteration 4\n",
      "[2020-10-30 20:31:02,128][src.learn_pdfa][INFO] Iteration 5\n",
      "[2020-10-30 20:31:03,694][src.learn_pdfa][INFO] Iteration 6\n",
      "[2020-10-30 20:31:05,386][src.learn_pdfa][INFO] Iteration 7\n",
      "[2020-10-30 20:31:07,646][src.learn_pdfa][INFO] Iteration 8\n",
      "[2020-10-30 20:31:09,288][src.learn_pdfa][INFO] Iteration 9\n",
      "[2020-10-30 20:31:10,910][src.learn_pdfa][INFO] Iteration 10\n",
      "[2020-10-30 20:31:12,895][src.learn_pdfa][INFO] Iteration 11\n",
      "[2020-10-30 20:31:14,830][src.learn_pdfa][INFO] Iteration 12\n",
      "[2020-10-30 20:31:16,725][src.learn_pdfa][INFO] Iteration 13\n",
      "[2020-10-30 20:31:18,750][src.learn_pdfa][INFO] Iteration 14\n",
      "[2020-10-30 20:31:20,359][src.learn_pdfa][INFO] Iteration 15\n",
      "[2020-10-30 20:31:21,612][src.learn_pdfa][INFO] Vertices: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "[2020-10-30 20:31:21,613][src.learn_pdfa][INFO] Transitions: {0: {0: 0, 3: 2, 4: 1},\n",
      " 1: {3: 3, 4: 4},\n",
      " 2: {0: 3, 7: 4},\n",
      " 3: {0: 6, 7: 5},\n",
      " 4: {3: 6, 4: 5},\n",
      " 5: {3: 7, 4: 7},\n",
      " 6: {0: 7, 7: 7}}\n",
      "[2020-10-30 20:31:21,614][src.learn_pdfa][INFO] Computed final node: 7 (no outgoing transitions)\n",
      "[2020-10-30 20:31:21,614][src.learn_pdfa][INFO] Renamed vertices: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "[2020-10-30 20:31:21,615][src.learn_pdfa][INFO] Renamed transitions: {0: {0: 0, 3: 2, 4: 1},\n",
      " 1: {3: 3, 4: 4},\n",
      " 2: {0: 3, 7: 4},\n",
      " 3: {0: 6, 7: 5},\n",
      " 4: {3: 6, 4: 5},\n",
      " 5: {3: 7, 4: 7},\n",
      " 6: {0: 7, 7: 7}}\n",
      "[2020-10-30 20:31:21,698][src.learn_pdfa][INFO] Number of vertices: 8.\n",
      "[2020-10-30 20:31:21,699][src.learn_pdfa][INFO] Transitions: {0: {0: 0, 3: 2, 4: 1},\n",
      " 1: {3: 3, 4: 4},\n",
      " 2: {0: 3, 7: 4},\n",
      " 3: {0: 6, 7: 5},\n",
      " 4: {3: 6, 4: 5},\n",
      " 5: {3: 7, 4: 7},\n",
      " 6: {0: 7, 7: 7}}.\n",
      "[2020-10-30 20:31:21,700][src.learn_pdfa][INFO] Start learning probabilities.\n",
      "[2020-10-30 20:31:21,700][src.learn_pdfa][INFO] Sample size: 930992363228525.\n",
      "[2020-10-30 20:31:21,701][src.learn_pdfa][INFO] Using N = 300000.\n",
      "[2020-10-30 20:31:39,121][src.learn_pdfa][INFO] Removing final state from the set of vertices.\n",
      "[2020-10-30 20:31:39,121][src.learn_pdfa][INFO] Computed vertices: {0, 1, 2, 3, 4, 5, 6}\n",
      "[2020-10-30 20:31:39,122][src.learn_pdfa][INFO] Computed transition dictionary: {0: {0: (0, 0.513136288998358),\n",
      "     3: (2, 0.24341817186644774),\n",
      "     4: (1, 0.24344553913519432)},\n",
      " 1: {3: (3, 0.4943494467782971), 4: (4, 0.5056505532217028)},\n",
      " 2: {0: (3, 0.5002362111727885), 7: (4, 0.4997637888272115)},\n",
      " 3: {0: (6, 0.5005310840362387), 7: (5, 0.4994689159637613)},\n",
      " 4: {3: (6, 0.4978962999628759), 4: (5, 0.5021037000371241)},\n",
      " 5: {3: (7, 0.5000979815794631), 4: (7, 0.49990201842053694)},\n",
      " 6: {0: (7, 0.5015376562193287), 7: (7, 0.49846234378067134)}}\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-15:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-9:\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "N = 300000\n",
    "mp_rdp_generator = MultiprocessedGenerator(rdp_generator, nb_processes=8)\n",
    "automaton = learn_pdfa(\n",
    "    sample_generator=mp_rdp_generator,\n",
    "    alphabet_size=rdp_generator.alphabet_size(),\n",
    "    epsilon=0.4,\n",
    "    delta_1=0.2,\n",
    "    delta_2=0.2,\n",
    "    mu=0.2,\n",
    "    n=3,\n",
    "    n1_max_debug=N,\n",
    "    n2_max_debug=N,\n",
    "    m0_max_debug=10000\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Learned graph (ignore the probabilities)\n",
    "tr = {\n",
    " 0: {0: (0, 0.3), 3: (1, 0.4), 4: (2, 0.3)},\n",
    " 1: {0: (3, 0.5), 7: (4, 0.5)},\n",
    " 2: {3: (3, 0.5), 4: (4, 0.5)},\n",
    " 3: {0: (5, 0.5), 7: (6, 0.5)},\n",
    " 4: {3: (5, 0.5), 4: (6, 0.5)},\n",
    " 5: {0: (7, 0.5), 7: (7, 0.5)},\n",
    " 6: {3: (7, 0.5), 4: (7, 0.5)}\n",
    "}\n",
    "automaton = PDFA(7, rdp_generator.alphabet_size(), tr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: PYDEVD_USE_CYTHON environment variable is set to 'NO'. Frame evaluator will be also disabled because it requires Cython extensions to be enabled in order to operate correctly.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The following states cannot reach the final state: {0, 1, 2, 3, 4, 5, 6, 7}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-32-ddb12bd5fa35>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# pydev_debug_cell\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mautomaton\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPDFA\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m8\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrdp_generator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0malphabet_size\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<string>\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, nb_states, alphabet_size, transition_dict)\u001B[0m\n",
      "\u001B[0;32m~/workfolder/PAC-RDPs-code/src/pdfa/base.py\u001B[0m in \u001B[0;36m__post_init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     45\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransition_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnb_states\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0malphabet_size\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m         )\n\u001B[0;32m---> 47\u001B[0;31m         \u001B[0m_check_ergodicity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransition_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnb_states\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfinal_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_successor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mState\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcharacter\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mCharacter\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mState\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workfolder/PAC-RDPs-code/src/pdfa/helpers.py\u001B[0m in \u001B[0;36m_check_ergodicity\u001B[0;34m(transitions, nb_states, final_state)\u001B[0m\n\u001B[1;32m     46\u001B[0m     assert_(\n\u001B[1;32m     47\u001B[0m         \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnonreachability_set\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m         \u001B[0;34mf\"The following states cannot reach the final state: {nonreachability_set}\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m     )\n\u001B[1;32m     50\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workfolder/PAC-RDPs-code/src/helpers/base.py\u001B[0m in \u001B[0;36massert_\u001B[0;34m(condition, message)\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;34m\"\"\"User-defined assert.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mcondition\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mAssertionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m: The following states cannot reach the final state: {0, 1, 2, 3, 4, 5, 6, 7}"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}